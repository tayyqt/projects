{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting job information from LinkedIn Jobs using BeautifulSoup and Selenium\n",
    "The goal of this project is to scrape job postings and related information from LinkedIn. We will be scraping infromation about 'Data Analyst' positions in 'Singapore'. After running the below code, we will get the following information about the job posting:\n",
    "\n",
    "1. Date  \n",
    "2. Title  \n",
    "3. Company Name  \n",
    "4. Location  \n",
    "5. Job Description  \n",
    "6. Job Level  \n",
    "7. Job Type  \n",
    "8. Function  \n",
    "9. Industry  \n",
    "10. Job ID  \n",
    "\n",
    "You can also use this code for different type of jobs with different location. To do that, follow the below process:  \n",
    "1. Open this link in a chrome incognito mode [https://www.linkedin.com/jobs/search/?f_TPR=r604800&geoId=101174742&keywords=data%20analyst&location=Canada&sortBy=DD]\n",
    "2. Specify to job title and location in the search bar.\n",
    "3. Copy and pase sortBy=DD& after location=(will show your searched location) in the weblink.\n",
    "4. Copy the final link and replace url variable with the new url in code block 2.\n",
    "5. To search data for more jobs, specify the numner of jobs (in multiple of 25 like 50 or 75 or 100 and so on) against variable called 'no_of_jobs' in code block 2.\n",
    "6. After all the above the steps are done, run the code  \n",
    "\n",
    "For this example, we will only look for 25 recent jobs. I hope you enjoy this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, timedelta, datetime\n",
    "from IPython.core.display import clear_output\n",
    "from random import randint\n",
    "from requests import get\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from time import sleep\n",
    "from time import time\n",
    "start_time = time()\n",
    "\n",
    "from warnings import warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace variables here.\n",
    "url = \"https://www.linkedin.com/jobs/search?keywords=data%20analyst&location=Singapore&sortBy=DD\"\n",
    "no_of_jobs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will open up new window with the url provided above \n",
    "#driver = webdriver.Chrome()\n",
    "driver = webdriver.Chrome(\"C:/Users/Test/OneDrive/Data Science/Automated Screenshot_v1/Automated Screenshot_v1/chromedriver.exe\")\n",
    "driver.get(url)\n",
    "sleep(3)\n",
    "action = ActionChains(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-f49dccad4b3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mActionChains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove_to_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbutton\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbutton\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# to show more jobs. Depends on number of jobs selected\n",
    "i = 2\n",
    "while i <= (no_of_jobs/25): \n",
    "    #driver.find_element_by_xpath('/html/body/main/div/section/button').click()\n",
    "    button = driver.find_element_by_xpath('/html/body/main/div/section/button')\n",
    "    driver.implicitly_wait(10)\n",
    "    ActionChains(driver).move_to_element(button).click(button).perform()\n",
    "    i = i + 1\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are scraping information about 1000 jobs.\n"
     ]
    }
   ],
   "source": [
    "# parsing the visible webpage\n",
    "pageSource = driver.page_source\n",
    "lxml_soup = BeautifulSoup(pageSource, 'lxml')\n",
    "\n",
    "# searching for all job containers\n",
    "job_container = lxml_soup.find('ul', class_ = 'jobs-search__results-list')\n",
    "\n",
    "print('You are scraping information about {} jobs.'.format(len(job_container)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error detected at posting number 282\n",
      "error detected at posting number 311\n",
      "error detected at posting number 501\n",
      "error detected at posting number 591\n",
      "error detected at posting number 649\n",
      "error detected at posting number 854\n"
     ]
    }
   ],
   "source": [
    "# setting up list for job information\n",
    "job_id = []\n",
    "post_title = []\n",
    "company_name = []\n",
    "post_date = []\n",
    "job_location = []\n",
    "job_desc = []\n",
    "level = []\n",
    "emp_type = []\n",
    "functions = []\n",
    "industries = []\n",
    "\n",
    "# for loop for job title, company, id, location and date posted\n",
    "for job in job_container:\n",
    "    \n",
    "    # job title\n",
    "    job_titles = job.find(\"span\", class_=\"screen-reader-text\").text\n",
    "    post_title.append(job_titles)\n",
    "    \n",
    "    # linkedin job id\n",
    "    job_ids = job.find('a', href=True)['href']\n",
    "    job_ids = re.findall(r'(?!-)([0-9]*)(?=\\?)',job_ids)[0]\n",
    "    job_id.append(job_ids)\n",
    "    \n",
    "    # company name\n",
    "    company_names = job.select_one('img')['alt']\n",
    "    company_name.append(company_names)\n",
    "    \n",
    "    # job location\n",
    "    job_locations = job.find(\"span\", class_=\"job-result-card__location\").text\n",
    "    job_location.append(job_locations)\n",
    "    \n",
    "    # posting date\n",
    "    post_dates = job.select_one('time')['datetime']\n",
    "    post_date.append(post_dates)\n",
    "\n",
    "# for loop for job description and criterias\n",
    "for x in range(1,len(job_id)+1):\n",
    "    \n",
    "    # clicking on different job containers to view information about the job\n",
    "    job_xpath = '/html/body/main/div/section/ul/li[{}]/img'.format(x)\n",
    "    driver.find_element_by_xpath(job_xpath).click()\n",
    "    sleep(1)\n",
    "    job_showmore_xpath = '/html/body/main/section/div[2]/section[2]/div/section/button[1]'.format(x)\n",
    "    try:\n",
    "        driver.find_element_by_xpath(job_showmore_xpath).click()\n",
    "    except:\n",
    "        print('error detected at posting number '+str(x))\n",
    "    sleep(2)\n",
    "    \n",
    "    # job description\n",
    "    #jobdesc_xpath = '/html/body/main/section/div[2]/section[2]/div'\n",
    "    jobdesc_xpath = '/html/body/main/section/div[2]/section[2]/div/section/div'\n",
    "    job_descs = driver.find_element_by_xpath(jobdesc_xpath).text\n",
    "    job_desc.append(job_descs)\n",
    "    \n",
    "    # job criteria container below the description\n",
    "    job_criteria_container = lxml_soup.find('ul', class_ = 'job-criteria__list')\n",
    "    all_job_criterias = job_criteria_container.find_all(\"span\", class_='job-criteria__text job-criteria__text--criteria')\n",
    "    \n",
    "    # Seniority level\n",
    "    seniority_xpath = '/html/body/main/section/div[2]/section[2]/ul/li[1]'\n",
    "    try:\n",
    "        seniority = driver.find_element_by_xpath(seniority_xpath).text.splitlines(0)[1]\n",
    "    except:\n",
    "        seniority = ''\n",
    "    level.append(seniority)\n",
    "    \n",
    "    # Employment type\n",
    "    type_xpath = '/html/body/main/section/div[2]/section[2]/ul/li[2]'\n",
    "    try:\n",
    "        employment_type = driver.find_element_by_xpath(type_xpath).text.splitlines(0)[1]\n",
    "    except:\n",
    "        employment_type = ''\n",
    "    emp_type.append(employment_type)\n",
    "    \n",
    "    # Job function\n",
    "    function_xpath = '/html/body/main/section/div[2]/section[2]/ul/li[3]'\n",
    "    try:\n",
    "        job_function = driver.find_element_by_xpath(function_xpath).text.splitlines(0)[1]\n",
    "    except:\n",
    "        job_function = ''\n",
    "    functions.append(job_function)\n",
    "    \n",
    "    # Industries\n",
    "    industry_xpath = '/html/body/main/section/div[2]/section[2]/ul/li[4]'\n",
    "    try:\n",
    "        industry_type = driver.find_element_by_xpath(industry_xpath).text.splitlines(0)[1]\n",
    "    except:\n",
    "        industry_type = ''\n",
    "    industries.append(industry_type)\n",
    "    \n",
    "    x = x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# to check if we have all information\n",
    "print(len(job_id))\n",
    "print(len(post_date))\n",
    "print(len(company_name))\n",
    "print(len(post_title))\n",
    "print(len(job_location))\n",
    "print(len(job_desc))\n",
    "print(len(level))\n",
    "print(len(emp_type))\n",
    "print(len(functions))\n",
    "print(len(industries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      "Company Name    1000 non-null object\n",
      "Date            1000 non-null object\n",
      "Description     1000 non-null object\n",
      "Function        1000 non-null object\n",
      "Industry        1000 non-null object\n",
      "Job ID          1000 non-null object\n",
      "Level           1000 non-null object\n",
      "Location        1000 non-null object\n",
      "Post            1000 non-null object\n",
      "Type            1000 non-null object\n",
      "dtypes: object(10)\n",
      "memory usage: 78.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Description</th>\n",
       "      <th>Function</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Job ID</th>\n",
       "      <th>Level</th>\n",
       "      <th>Location</th>\n",
       "      <th>Post</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FWD Insurance</td>\n",
       "      <td>2020-08-15</td>\n",
       "      <td>What we do At the COMO Group,  we bring togeth...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1964677764</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nanyang Technological University</td>\n",
       "      <td>2020-08-15</td>\n",
       "      <td>FWD spans Hong Kong, Macau, Thailand, Indonesi...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>1991314937</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>Trainee, Research Data Analyst [#SGUnitedTrain...</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NTT Ltd.</td>\n",
       "      <td>2020-08-14</td>\n",
       "      <td>Programme Summary  In conjunction with Workfor...</td>\n",
       "      <td>ResearchAnalystInformation Technology</td>\n",
       "      <td>Higher EducationResearchHospital &amp; Health Care</td>\n",
       "      <td>1991234687</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Predictive Data Analyst</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RBi</td>\n",
       "      <td>2020-08-14</td>\n",
       "      <td>Predictive Data Analyst In a constantly changi...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Information Technology and ServicesComputer So...</td>\n",
       "      <td>1991234298</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>Senior Analyst, circular plastics Asia-Pacific</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inland Revenue Authority of Singapore (IRAS)</td>\n",
       "      <td>2020-08-14</td>\n",
       "      <td>Why Work for Us In ICIS, we connect data, mark...</td>\n",
       "      <td>ResearchAnalystInformation Technology</td>\n",
       "      <td>Information Technology and ServicesInternetFin...</td>\n",
       "      <td>1964666262</td>\n",
       "      <td>Associate</td>\n",
       "      <td>South West Community Development Council, Sing...</td>\n",
       "      <td>Senior Data Scientist / Data Scientist / Data ...</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Company Name        Date  \\\n",
       "0                                 FWD Insurance  2020-08-15   \n",
       "1              Nanyang Technological University  2020-08-15   \n",
       "2                                      NTT Ltd.  2020-08-14   \n",
       "3                                           RBi  2020-08-14   \n",
       "4  Inland Revenue Authority of Singapore (IRAS)  2020-08-14   \n",
       "\n",
       "                                         Description  \\\n",
       "0  What we do At the COMO Group,  we bring togeth...   \n",
       "1  FWD spans Hong Kong, Macau, Thailand, Indonesi...   \n",
       "2  Programme Summary  In conjunction with Workfor...   \n",
       "3  Predictive Data Analyst In a constantly changi...   \n",
       "4  Why Work for Us In ICIS, we connect data, mark...   \n",
       "\n",
       "                                Function  \\\n",
       "0                                          \n",
       "1                 Information Technology   \n",
       "2  ResearchAnalystInformation Technology   \n",
       "3                 Information Technology   \n",
       "4  ResearchAnalystInformation Technology   \n",
       "\n",
       "                                            Industry      Job ID  \\\n",
       "0                                                     1964677764   \n",
       "1                                          Insurance  1991314937   \n",
       "2     Higher EducationResearchHospital & Health Care  1991234687   \n",
       "3  Information Technology and ServicesComputer So...  1991234298   \n",
       "4  Information Technology and ServicesInternetFin...  1964666262   \n",
       "\n",
       "            Level                                           Location  \\\n",
       "0  Not Applicable                                          Singapore   \n",
       "1       Associate                               Singapore, Singapore   \n",
       "2      Internship                                          Singapore   \n",
       "3     Entry level                               Singapore, Singapore   \n",
       "4       Associate  South West Community Development Council, Sing...   \n",
       "\n",
       "                                                Post       Type  \n",
       "0                                   Business Analyst  Full-time  \n",
       "1  Trainee, Research Data Analyst [#SGUnitedTrain...  Full-time  \n",
       "2                            Predictive Data Analyst  Full-time  \n",
       "3     Senior Analyst, circular plastics Asia-Pacific  Full-time  \n",
       "4  Senior Data Scientist / Data Scientist / Data ...  Full-time  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dataframe\n",
    "job_data = pd.DataFrame({'Job ID': job_id,\n",
    "'Date': post_date,\n",
    "'Company Name': company_name,\n",
    "'Post': post_title,\n",
    "'Location': job_location,\n",
    "'Description': job_desc,\n",
    "'Level': level,\n",
    "'Type': emp_type,\n",
    "'Function': functions,\n",
    "'Industry': industries\n",
    "})\n",
    "\n",
    "# cleaning description column\n",
    "job_data['Description'] = job_data['Description'].str.replace('\\n',' ')\n",
    "\n",
    "print(job_data.info())\n",
    "job_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data.to_csv('data.csv', index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Author: Amandeep Saluja"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
